# -*- coding: utf-8 -*-
"""GROUP PROJECT DTR Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jTr7bkLfsyvzFt8spLpQd29uy-6Sio7N
"""

# Import libraries
import pandas as pd
import numpy as np
from plotnine import *
import matplotlib.pyplot as plt
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import metrics

import datetime as dt
import statsmodels.api as sm
import statsmodels.formula.api as smf

from statsmodels.graphics.tsaplots import plot_acf
from statsmodels.graphics.tsaplots import plot_pacf

from statsmodels.tsa.api import ExponentialSmoothing

def rmse(actual,predicted):
    return round(((actual - predicted)**2).mean()**0.5,3)

def mape(actual,predicted):
    return round(abs((actual - predicted)/actual).mean()*100,3)

def accuracy(actual,predicted,h=0):
    n_train = len(actual) - h
    accuracy_metrics = pd.DataFrame(columns=['RMSE','MAPE(%)'],index=['Training set','Testing set'])
    accuracy_metrics.loc['Training set','RMSE'] = rmse(actual[:n_train],predicted[:n_train])
    accuracy_metrics.loc['Training set','MAPE(%)'] = mape(actual[:n_train],predicted[:n_train])
    if (h>0):
        accuracy_metrics.loc['Testing set','RMSE'] = rmse(actual[n_train:],predicted[n_train:])
        accuracy_metrics.loc['Testing set','MAPE(%)'] = mape(actual[n_train:],predicted[n_train:])
    return accuracy_metrics

myDF = pd.read_csv('https://raw.githubusercontent.com/laneyhlc/DSO424/main/CompetitionData.csv')

myDF.info()

myDF['Date'] = pd.to_datetime(myDF['Date'])

print(myDF[myDF['Load'].isna()])
# 35063 and above are going to be for my train/test

print(myDF.iloc[35063])
print()
print(myDF.iloc[35064])

myDF[:35064]

myDF['Trend'] = list(range(0,len(myDF)))

myDF['Date1'] = pd.to_datetime(myDF['Date']).dt.date
myDF['Time'] = pd.to_datetime(myDF['Date']).dt.time

myDF

myDF['TimeDummies'] = myDF['Time']

myDF = pd.get_dummies(myDF,prefix='',prefix_sep='',columns=['TimeDummies'])
myDF.head(2)

myDF['Temp'] = myDF['Temperature']

print(myDF.corr())
# it seems like load is the target variable
# and temperature and data as well as hour are features

# Step 1: define y and X and then split them into training and testing sets
y = myDF['Load']
X = myDF.loc[:, '00:00:00':'Temp'] #  all rows from columns '00:00:00' to the end

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 8784, shuffle = False) # text size = 8784 because there are 8784 NaN loads we don't know

# Step 2: build a model using training set
# create a decision tree regressor object
M1 = DecisionTreeRegressor(criterion='squared_error', splitter='best', max_depth=None, min_samples_split=2, 
                          min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, 
                          random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, ccp_alpha=0.0)

# Train a model(fit a model) using data, i.e. X_train and y_train
M1.fit(X_train,y_train)

# Step 3: predict on both training and testing set
myDF['M1'] = M1.predict(X)

myDF2 = myDF[:35064]

# Step 4: evaluate model's performance
accuracy(myDF2['Load'],myDF2['M1'],h=8784)

